# ##############################################################################################
# see also https://github.com/simplesteph/kafka-stack-docker-compose/blob/master/full-stack.yml
# ##############################################################################################
version: '3'
services:

  kdc-zookeeper:
    image: "confluentinc/cp-zookeeper:5.5.0"
    container_name: "kdc-zookeeper"
    ports:
      - "30000:2181"
      - "30010:30010"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_JMX_PORT: 30010
      KAFKA_JMX_OPTS: "-Djava.rmi.server.hostname=maxant.ch -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.rmi.port=30010"
      KAFKA_JMX_HOSTNAME: maxant.ch
    #volumes:
    #  - ./full-stack/zoo1/data:/data
    #  - ./full-stack/zoo1/datalog:/datalog

  kdc-kafka-1:
    image: "maxant/kafka"
    container_name: "kdc-kafka-1"
    ports:
      - "30001:9092"
      - "30011:30011"
    depends_on:
      - kdc-zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'kdc-zookeeper:2181'
      # see: https://rmoff.net/2018/08/02/kafka-listeners-explained/
      # note that we MUST use "PLAINTEXT" as the name, so that schemaregistry and kafka-rest can connect.
      # see: https://github.com/confluentinc/schema-registry/issues/648
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://maxant.ch:30001
      KAFKA_LISTENERS: PLAINTEXT://kdc-kafka-1:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: "false"
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_NUM_PARTITIONS: 5
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://kdc-schemaregistry:8085
      KAFKA_JMX_PORT: 30011
      KAFKA_JMX_OPTS: "-Djava.rmi.server.hostname=maxant.ch -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.rmi.port=30011"
      KAFKA_JMX_HOSTNAME: maxant.ch
      KAFKA_OPTS: -javaagent:/usr/app/jmx_prometheus_javaagent.jar=7071:/usr/app/prom-jmx-agent-config.yml
    #volumes:
    #  - ./full-stack/kafka1/data:/var/lib/kafka/data

  kdc-kafka-2:
    image: "maxant/kafka"
    container_name: "kdc-kafka-2"
    ports:
      - "30002:9092"
      - "30012:30012"
    depends_on:
      - kdc-kafka-1
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: 'kdc-zookeeper:2181'
      # see notes for broker #1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://maxant.ch:30002
      KAFKA_LISTENERS: PLAINTEXT://kdc-kafka-2:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: "false"
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_NUM_PARTITIONS: 5
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://kdc-schemaregistry:8085
      KAFKA_JMX_PORT: 30012
      KAFKA_JMX_OPTS: "-Djava.rmi.server.hostname=maxant.ch -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.rmi.port=30012"
      KAFKA_JMX_HOSTNAME: maxant.ch
      KAFKA_OPTS: -javaagent:/usr/app/jmx_prometheus_javaagent.jar=7071:/usr/app/prom-jmx-agent-config.yml
    #volumes:
    #  - ./full-stack/kafka1/data:/var/lib/kafka/data

  kdc-kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: "kdc-kafdrop"
    ports:
      - "30060:9000"
    depends_on:
      - kdc-kafka-1
      - kdc-kafka-2
      - kdc-schemaregistry
    environment:
      KAFKA_BROKERCONNECT: "kdc-kafka-1:9092,kdc-kafka-2:9092"
      SCHEMAREGISTRY_CONNECT: "http://kdc-schemaregistry:8085"
  portainer:
    image: "portainer/portainer"
    container_name: "portainer"
    ports:
      - "29999:9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /portainer_data:/data

#  cadvisor:
#    image: google/cadvisor:latest
#    container_name: cadvisor
#    ports:
#      - "29998:8080"
#    volumes:
#      - /var/lib/docker/:/var/lib/docker:ro
#      - /sys:/sys:ro
#      - /var/run:/var/run:rw
#      - /:/rootfs:ro

  kdc-mysql:
    image: "mysql:8.0.19"
    container_name: "kdc-mysql"
    ports:
      - "30300:3306"
    environment:
      MYSQL_ROOT_PASSWORD: "secret"
    volumes:
      - ./mysql-data:/var/lib/mysql:rw

  # https://github.com/confluentinc/cp-demo/blob/5.5.0-post/docker-compose.yml
  kdc-schemaregistry:
    image: "confluentinc/cp-schema-registry:5.5.0"
    container_name: "kdc-schemaregistry"
    ports:
      - 30550:8085
    depends_on:
      - kdc-kafka-1
      - kdc-kafka-2
    environment:
      CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-security/schema-registry/*:/usr/share/java/schema-registry/*'
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kdc-kafka-1:9092,kdc-kafka-2:9092
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: kdc-zookeeper:2181
      SCHEMA_REGISTRY_HOST_NAME: kdc-schemaregistry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8085
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: INFO
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
      SCHEMA_REGISTRY_DEBUG: 'true'
      # Used by Schema Registry to connect to MDS to authenticate and authorize clients:
      SCHEMA_REGISTRY_CONFLUENT_METADATA_BOOTSTRAP_SERVER_URLS: http://kdc-kafka-1:9092,http://kdc-kafka-2:9092

  kdc-schemaregistry-ui:
    image: "landoop/schema-registry-ui:0.9.4"
    container_name: "kdc-schemaregistry-ui"
    ports:
      - "30555:8000"
    depends_on:
      - kdc-schemaregistry
    environment:
      SCHEMAREGISTRY_URL: http://kdc.schemaregistry.maxant.ch/
      PROXY: "true"

  kdc-kafka-rest-proxy:
    image: "confluentinc/cp-kafka-rest:5.5.0"
    container_name: "kdc-kafka-rest-proxy"
    ports:
      - "30030:8082"
    depends_on:
      - kdc-schemaregistry
    environment:
      # KAFKA_REST_ZOOKEEPER_CONNECT: zoo1:2181
      KAFKA_REST_LISTENERS: http://0.0.0.0:8082/
      KAFKA_REST_SCHEMA_REGISTRY_URL: http://kdc-schemaregistry:8085/
      KAFKA_REST_HOST_NAME: kdc-kafka-rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: PLAINTEXT://kdc-kafka-1:9092,PLAINTEXT://kdc-kafka-2:9092

  # https://www.elastic.co/guide/en/elastic-stack-get-started/current/get-started-docker.html
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.1
    container_name: "elasticsearch"
    ports:
      - "30050:9200"
      - "30051:9300"
    environment:
      "node.name": "elasticsearch"
      "bootstrap.memory_lock": "true"
      "discovery.type": "single-node"
      "ES_JAVA_OPTS": "-Xms1g -Xmx1g"
      "http.cors.allow-origin": "*"
      "http.cors.enabled": "true"
      "http.cors.allow-headers": "X-Requested-With,X-Auth-Token,Content-Type,Content-Length,Authorization"
      "http.cors.allow-credentials": "true"
    volumes:
      - ./es-data:/usr/share/elasticsearch/data
  logstash:
    image: docker.elastic.co/logstash/logstash:7.10.1
    container_name: "logstash"
    ports:
      - "30055:12201/udp"
      - "30056:5000"
      - "30057:9600"
    depends_on:
      - elasticsearch
    volumes:
      - ./pipelines:/usr/share/logstash/pipeline
    #environment:
      # https://www.elastic.co/guide/en/logstash/7.10/docker-config.html#docker-env-config
      # not defined in oss image:
      #"monitoring.elasticsearch.hosts": "http://kdc.elasticsearch.maxant.ch1"
      #"MONITORING_ELASTICSEARCH_HOSTS": "http://kdc.elasticsearch.maxant.ch2"
  kibana:
    image: docker.elastic.co/kibana/kibana:7.10.1
    container_name: "kibana"
    ports:
      - "30150:5601"
    depends_on:
      - elasticsearch
    links:
      - "elasticsearch:elasticsearch"
    #environment:
      # https://www.elastic.co/guide/en/kibana/current/settings.html
      #"ELASTICSEARCH_HOSTS": "http://kdc.elasticsearch.maxant.ch"
      #"ELASTICSEARCH_HOSTS": "http://maxant.ch:30050" => doesnt work entirely because somehow it still cannot connect. maybe to 9300 instead of 9200?
      #"XPACK_SECURITY_ENABLED": "false"
      # seems to work out of the box, when we name ES "elasticsearch"
    #https://www.elastic.co/guide/en/kibana/current/docker.html
    #volumes:
    #  - ./kibana.yml:/usr/share/kibana/config/kibana.yml

  prometheus:
    image: "prom/prometheus"
    container_name: "prometheus"
    ports:
      - "29996:9090/tcp"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro

  grafana:
    image: "grafana/grafana"
    container_name: "grafana"
    ports:
      - 29993:3000
    depends_on:
      - prometheus
    volumes:
      - ./grafanadata:/var/lib/grafana

  jaeger-agent:
    image: jaegertracing/jaeger-agent:1.21.0
    container_name: jaeger-agent
    # to get help, run this: docker run -it --rm jaegertracing/jaeger-agent:1.21.0 --help
    # to add command line args, use the command:
    command: --reporter.grpc.host-port=jaeger-collector:14250
    ports:
      # thrift compact:
      - "30561:6831/udp"
      # thrift binary:
      - "30562:6832/udp"
      # HTTP serve configs, sampling strategies:
      - "30563:5778"
      # zipkin thrift compact:
      - "30564:5775"
      # admin port: health check at / and metrics at /metrics:
      - "30565:14271"
    depends_on:
      - jaeger-collector

  jaeger-collector:
    image: jaegertracing/jaeger-collector:1.21.0
    container_name: jaeger-collector
    environment:
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://elasticsearch:9200
    ports:
      # gRPC, used by jaeger-agent to send spans in model.proto format:
      - "30566:14250"
      # HTTP, can accept spans directly from clients in jaeger.thrift format over binary thrift protocol:
      - "30567:14268"
      # HTTP, can accept Zipkin spans in Thrift, JSON and Proto (disabled by default)
      - "30568:9411"
      # HTTP, admin port: health check at / and metrics at /metrics
      - "30569:14269"
    depends_on:
      - elasticsearch

  jaeger-query:
    image: jaegertracing/jaeger-query:1.21.0
    container_name: jaeger-query
    environment:
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://elasticsearch:9200
    ports:
      # HTTP, /api/* endpoints and Jaeger UI at /
      - "30570:16686"
      # Protobuf/gRPC QueryService
      - "30571:16686"
      # HTTP, admin port: health check at / and metrics at /metrics
      - "30572:16687"
    depends_on:
      - elasticsearch
      - jaeger-agent
      - jaeger-collector

  redis:
    image: redis:6.2.1-alpine
    container_name: kdc-redis
    ports:
      - "30580:6379"
    command: redis-server --maxmemory 64mb --maxmemory-policy allkeys-lru --bind 127.0.0.1 172.18.0.0/24 88.61.17.202 --requirepass supersecretpsswrd
    # or to use a config file: -v /myredis/conf:/usr/local/etc/redis redis redis-server /usr/local/etc/redis/redis.conf
    ulimits:
      memlock: "-1:-1"

# TODO https://docs.docker.com/compose/compose-file/#healthcheck
# TODO https://docs.docker.com/compose/compose-file/#restart
# TODO JMX for other confluent components: https://docs.confluent.io/current/installation/docker/operations/monitoring.html#configure-other-cp-components
# build a stream app and deploy using quarkus and integrate metrics - see also https://quarkus.io/guides/microprofile-metrics
# use kafka-rest to add topics at deployment. whats this? https://docs.docker.com/compose/compose-file/compose-file-v2/#init
